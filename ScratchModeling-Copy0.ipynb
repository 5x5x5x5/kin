{
 "metadata": {
  "name": "",
  "signature": "sha256:750af090a49852a5750a39e90daea53802808923f9df310b7f40adaad418af1e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load file into a dataframe"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls data/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[01;32m1a2.csv\u001b[0m*   \u001b[01;32m2c9.csv\u001b[0m*  \u001b[01;32m3a4.csv\u001b[0m*                            balanced2c19.csv\r\n",
        "\u001b[01;32m2c19.csv\u001b[0m*  \u001b[01;32m2d6.csv\u001b[0m*  \u001b[01;32mSIDWashedstructureDescriptors.csv\u001b[0m*\r\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twoC19 = pd.read_csv(\"data/balanced2c19.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train-Test Split!\n",
      "Cross validation of model performance by holding back 20% of the data and assessing the model on that set after training the model on the 80% retained."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get descriptor matrix as numpy array\n",
      "\n",
      "X = twoC19.ix[:,'apol':'zagreb']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twoC19['inhibitor'] = 0\n",
      "twoC19.inhibitor[twoC19.ActivityScore >= 40] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twoC19.inhibitor.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "0    0\n",
        "1    0\n",
        "2    1\n",
        "3    1\n",
        "4    1\n",
        "5    1\n",
        "6    0\n",
        "7    1\n",
        "8    0\n",
        "9    1\n",
        "Name: inhibitor, dtype: int64"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = twoC19.ix[:,'inhibitor']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This didn't work\n",
      "\n",
      "# Declare activity scores below 40 as inactive inhibitors\n",
      "# Declare activity scores 40 and above as active inhibitors\n",
      "# Get predictors as numpy array\n",
      "\n",
      "# twoC19.where('ActivityScore' < 40, 0)\n",
      "# twoC19.where('ActivityScore' >= 40, 1)\n",
      "# y = twoC19.ix[:,'ActivityScore']\n",
      "\n",
      "# y.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twoC19.ActivityScore.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "count    11828.000000\n",
        "mean        33.475566\n",
        "std         31.877036\n",
        "min          0.000000\n",
        "25%          0.000000\n",
        "50%         34.500000\n",
        "75%         45.000000\n",
        "max        108.000000\n",
        "Name: ActivityScore, dtype: float64"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "# create 80%-20% train-test split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "((9462, 186), (2366, 186), (9462,), (2366,))"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.neighbors import KNeighborsClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kNNestimate = KNeighborsClassifier(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kNNestimate.fit(X_train, y_train)  # fit kNN model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           n_neighbors=3, p=2, weights='uniform')"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_predict = kNNestimate.predict(X_test) # validate using test data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([1, 1, 1, ..., 0, 1, 0])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_predict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "array([1, 1, 1, ..., 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      " \n",
      "cm = confusion_matrix(y_test, y_predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[798 389]\n",
        " [334 845]]\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      " \n",
      "cr = classification_report(y_test, y_predict)\n",
      " \n",
      "print(cr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.70      0.67      0.69      1187\n",
        "          1       0.68      0.72      0.70      1179\n",
        "\n",
        "avg / total       0.69      0.69      0.69      2366\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}